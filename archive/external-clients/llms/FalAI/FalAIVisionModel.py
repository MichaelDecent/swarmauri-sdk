import os
import fal_client
import asyncio
from typing import List, Literal, Dict
from pydantic import Field, ConfigDict
from swarmauri.llms.base.LLMBase import LLMBase


class FalAIVisionModel(LLMBase):
    """
    A model for processing images and answering questions using vision models provided by FalAI.
    This class allows both synchronous and asynchronous processing of images based on prompts.

    Attributes:
        allowed_models (List[str]): List of allowed model names for vision tasks.
        api_key (str): The API key for authenticating with FalAI services.
        model_name (str): The model name to use for processing images.
        type (Literal): The type identifier for the model.
        model_config (ConfigDict): Configuration dictionary with protected namespaces.

    Link to API KEY: https://fal.ai/dashboard/keys
    Link to Allowed Models: https://fal.ai/models?categories=vision
    """

    allowed_models: List[str] = [
        "fal-ai/llava-next",
        "fal-ai/llavav15-13b",
        "fal-ai/any-llm/vision",
    ]
    api_key: str = Field(default_factory=lambda: os.environ.get("FAL_KEY"))
    model_name: str = Field(default="fal-ai/llava-next")
    type: Literal["FalAIVisionModel"] = "FalAIVisionModel"

    model_config = ConfigDict(protected_namespaces=())

    def __init__(self, **data):
        """
        Initializes the FalAIVisionModel with API key, model name, and validation of the model name.

        Args:
            **data: Additional keyword arguments passed to initialize the model.

        Raises:
            ValueError: If the provided model_name is not in allowed_models.
        """
        super().__init__(**data)
        if self.api_key:
            os.environ["FAL_KEY"] = self.api_key
        if self.model_name not in self.allowed_models:
            raise ValueError(
                f"Invalid model name. Allowed models are: {', '.join(self.allowed_models)}"
            )

    def _send_request(self, image_url: str, prompt: str, **kwargs) -> Dict:
        """
        Sends a request to the vision model API to process an image and answer a question.

        Args:
            image_url (str): URL of the image to be processed.
            prompt (str): Text prompt for the vision model to answer based on the image.
            **kwargs: Additional arguments for the API request.

        Returns:
            Dict: The API response containing the answer and other response details.
        """
        arguments = {"image_url": image_url, "prompt": prompt, **kwargs}
        result = fal_client.subscribe(
            self.model_name,
            arguments=arguments,
            with_logs=True,
        )
        return result

    def process_image(self, image_url: str, prompt: str, **kwargs) -> str:
        """
        Processes an image and returns an answer to the question based on the prompt.

        Args:
            image_url (str): URL of the image to be processed.
            prompt (str): Question or prompt to ask about the image.
            **kwargs: Additional arguments for the request.

        Returns:
            str: Answer generated by the vision model.
        """
        response_data = self._send_request(image_url, prompt, **kwargs)
        return response_data["output"]

    async def aprocess_image(self, image_url: str, prompt: str, **kwargs) -> str:
        """
        Asynchronously processes an image and returns an answer based on the prompt.

        Args:
            image_url (str): URL of the image to be processed.
            prompt (str): Question or prompt to ask about the image.
            **kwargs: Additional arguments for the request.

        Returns:
            str: Answer generated by the vision model.
        """
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None, self.process_image, image_url, prompt, **kwargs
        )

    def batch(self, image_urls: List[str], prompts: List[str], **kwargs) -> List[str]:
        """
        Processes a batch of images and returns answers for each.

        Args:
            image_urls (List[str]): List of URLs of images to be processed.
            prompts (List[str]): List of prompts/questions for each image.
            **kwargs: Additional arguments for each request.

        Returns:
            List[str]: List of answers generated by the vision model.
        """
        answers = []
        for image_url, prompt in zip(image_urls, prompts):
            answer = self.process_image(image_url=image_url, prompt=prompt, **kwargs)
            answers.append(answer)
        return answers

    async def abatch(
        self,
        image_urls: List[str],
        prompts: List[str],
        max_concurrent: int = 5,
        **kwargs,
    ) -> List[str]:
        """
        Asynchronously processes a batch of images and returns answers for each.

        Args:
            image_urls (List[str]): List of URLs of images to be processed.
            prompts (List[str]): List of prompts/questions for each image.
            max_concurrent (int): Maximum number of concurrent requests. Default is 5.
            **kwargs: Additional arguments for each request.

        Returns:
            List[str]: List of answers generated by the vision model.
        """
        semaphore = asyncio.Semaphore(max_concurrent)

        async def process_image_prompt(image_url, prompt):
            async with semaphore:
                return await self.aprocess_image(
                    image_url=image_url, prompt=prompt, **kwargs
                )

        tasks = [
            process_image_prompt(image_url, prompt)
            for image_url, prompt in zip(image_urls, prompts)
        ]
        return await asyncio.gather(*tasks)

    @staticmethod
    def upload_file(file_path: str) -> str:
        """
        Uploads a file and returns its URL for use with the vision model.

        Args:
            file_path (str): Local file path of the image to be uploaded.

        Returns:
            str: URL of the uploaded file for access in API requests.
        """
        return fal_client.upload_file(file_path)
